{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2097406,"sourceType":"datasetVersion","datasetId":1257880},{"sourceId":8926479,"sourceType":"datasetVersion","datasetId":5329559}],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install ultralytics ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import cv2\nimport numpy as np\nimport os\nfrom PIL import Image\nimport pandas as pd \nfrom ultralytics import YOLO\nimport cv2\nimport torch\nfrom sklearn.linear_model import LinearRegression\n\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2024-08-14T07:01:45.779625Z","iopub.execute_input":"2024-08-14T07:01:45.780029Z","iopub.status.idle":"2024-08-14T07:01:50.779050Z","shell.execute_reply.started":"2024-08-14T07:01:45.779993Z","shell.execute_reply":"2024-08-14T07:01:50.777680Z"},"trusted":true},"outputs":[],"execution_count":4},{"cell_type":"code","source":"BEST_WEIGHT = '/kaggle/input/osteoga-model/OsteoGA_model/segmentation/weights/oai_s_best4.pt'\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\ndef create_model(weight_path=None):\n    if weight_path:\n        return YOLO(weight_path)\n    else:\n        return YOLO(BEST_WEIGHT)\n\nclass Segmenter():\n    def __init__(self, weight_path=None):\n        self.model = create_model(weight_path).to(DEVICE)\n    \n    def segment(self, img):\n        \"\"\"\n            input: image (H, W, C)\n            output: mask (H, W) with femur is 1 and tibia is 2 \n        \"\"\"\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n\n        eimg = cv2.equalizeHist(img)\n\n        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n        eimg = clahe.apply(eimg)\n\n        eimg = cv2.cvtColor(eimg, cv2.COLOR_GRAY2RGB)\n\n        res = self.model(eimg, verbose=False)\n\n        mask = res[0].masks.data[0] * (res[0].boxes.cls[0] + 1) + res[0].masks.data[1] * (res[0].boxes.cls[1] + 1)\n        mask = mask.cpu().numpy()\n\n        return mask","metadata":{"execution":{"iopub.status.busy":"2024-08-14T07:01:50.780455Z","iopub.execute_input":"2024-08-14T07:01:50.781133Z","iopub.status.idle":"2024-08-14T07:01:50.791981Z","shell.execute_reply.started":"2024-08-14T07:01:50.781094Z","shell.execute_reply":"2024-08-14T07:01:50.790489Z"},"trusted":true},"outputs":[],"execution_count":5},{"cell_type":"code","source":"def center(contour):\n    idx = len(contour) // 2\n    return contour[idx]\n\n\ndef to_color(image):\n    if len(image.shape) == 3 and image.shape[-1] == 3:\n        return image\n    return cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n\n\ndef to_gray(image):\n    if len(image.shape) == 3 and image.shape[-1] == 3:\n        return cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n    return image","metadata":{"execution":{"iopub.status.busy":"2024-08-14T07:01:50.795227Z","iopub.execute_input":"2024-08-14T07:01:50.795718Z","iopub.status.idle":"2024-08-14T07:01:50.825055Z","shell.execute_reply.started":"2024-08-14T07:01:50.795678Z","shell.execute_reply":"2024-08-14T07:01:50.823872Z"},"trusted":true},"outputs":[],"execution_count":6},{"cell_type":"code","source":"def detect_limit_points(mask, verbose=0):\n    # tìm giới hạn hai bên của khớp gối\n    '''\n        input: mask (H, W) with femur is 1 and tibia is 2\n        output: 4 points serve as limit points to determine the upper and lower contours from the full contours of the femur and tibia\n    '''\n    h, w = mask.shape\n    res = []\n    upper_pivot = np.array([0, w // 2])  # r c\n    lower_pivot = np.array([h, w // 2])  # r c\n\n    left_slice = slice(0, w // 2)\n    right_slice = slice(w // 2, None)\n    center_slice = slice(int(0.2 * h), int(0.8 * h))\n\n    left = np.zeros_like(mask)\n    left[center_slice, left_slice] = mask[center_slice, left_slice]\n\n    right = np.zeros_like(mask)\n    right[center_slice, right_slice] = mask[center_slice, right_slice]\n\n    if verbose:\n        cv2_imshow([left, right])\n\n    pivot = np.array([0, w])\n    coords = np.argwhere(left == 1)\n    distances = ((coords - pivot) ** 2).sum(axis=-1)\n    point = coords[distances.argmax()][::-1]\n    res.append(point)\n\n    pivot = np.array([0, 0])\n    coords = np.argwhere(right == 1)\n    distances = ((coords - pivot) ** 2).sum(axis=-1)\n    point = coords[distances.argmax()][::-1]\n    res.append(point)\n\n    pivot = np.array([h, w])\n    coords = np.argwhere(left == 2)\n    distances = ((coords - pivot) ** 2).sum(axis=-1)\n    point = coords[distances.argmax()][::-1]\n    res.append(point)\n\n    pivot = np.array([h, 0])\n    coords = np.argwhere(right == 2)\n    distances = ((coords - pivot) ** 2).sum(axis=-1)\n    point = coords[distances.argmax()][::-1]\n    res.append(point)\n\n    if verbose:\n        cv2_imshow(draw_points(127 * mask, res))\n\n    return res\n\ndef find_boundaries(mask, start, end, top=True, verbose=0):\n    #     nếu top = True, tìm đường bao bên trên cùng từ left đến right\n    #     nếu top = False, tìm đường bao dưới cùng từ left đến right\n    '''\n        input:  \n            mask (H, W) of femur or tibia \n            start, end is limit point to extract upper_contour/lower_contour from femur/tibia full contour\n        output: upper_contour/lower_contour\n        use top = True if determine lower contour from tibia mask\n    '''\n    boundaries = []\n    height, width = mask.shape\n\n    contours, _ = cv2.findContours(255 * mask.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n\n    areas = np.array([cv2.contourArea(cnt) for cnt in contours])\n    contour = contours[areas.argmax()]\n    contour = contour.reshape(-1, 2)\n    org_contour = contour.copy()\n\n    start_idx = ((start - contour) ** 2).sum(axis=-1).argmin()\n    end_idx = ((end - contour) ** 2).sum(axis=-1).argmin()\n    if start_idx <= end_idx:\n        contour = contour[start_idx:end_idx + 1]\n    else:\n        contour = np.concatenate([contour[start_idx:], contour[:end_idx + 1]])\n\n    if top:\n        sorted_indices = np.argsort(contour[:, 1])[::-1]\n    else:\n        sorted_indices = np.argsort(contour[:, 1])\n    contour = contour[sorted_indices]\n\n    unique_indices = sorted(np.unique(contour[:, 0], return_index=True)[1])\n    contour = contour[unique_indices]\n    sorted_indices = np.argsort(contour[:, 0])\n    contour = contour[sorted_indices]\n    if verbose:\n        temp = draw_points(127 * mask.astype(np.uint8), contour, thickness=5)\n        temp = draw_points(temp, [start, end], color=[155, 155], thickness=15)\n        # cv2_imshow(temp)\n\n    return np.array(contour), np.array(org_contour)\n\n\ndef get_contours(mask, verbose=0):\n    '''\n        input: mask (H, W) with femur is 1 and tibia is 2\n        output: upper_contour, lower_contour\n    '''\n    limit_points = detect_limit_points(mask, verbose=verbose)\n    upper_contour, full_upper = find_boundaries(mask == 1, limit_points[0], limit_points[1], top=False, verbose=verbose)\n    lower_contour, full_lower = find_boundaries(mask == 2, limit_points[3], limit_points[2], top=True, verbose=verbose)\n    if verbose:\n        temp = draw_points(127 * mask, full_upper, thickness=3, color=(255, 0, 0))\n        temp = draw_points(temp, full_lower, thickness=3)\n        # cv2_imshow(temp)\n        # cv2.imwrite('full.png', temp)\n        temp = draw_points(temp, limit_points, thickness=7, color=(0, 0, 255))\n        # cv2_imshow(temp)\n        # cv2.imwrite('limit_points.png', temp)\n    if verbose:\n        temp = draw_points(127 * mask, upper_contour, thickness=3, color=(255, 0, 0))\n        temp = draw_points(temp, lower_contour, thickness=3)\n        # cv2_imshow(temp)\n        # cv2.imwrite('cropped.png', temp)\n\n    return upper_contour, lower_contour","metadata":{"execution":{"iopub.status.busy":"2024-08-14T07:01:50.826702Z","iopub.execute_input":"2024-08-14T07:01:50.827168Z","iopub.status.idle":"2024-08-14T07:01:50.853516Z","shell.execute_reply.started":"2024-08-14T07:01:50.827126Z","shell.execute_reply":"2024-08-14T07:01:50.851955Z"},"trusted":true},"outputs":[],"execution_count":7},{"cell_type":"code","source":"def distance(mask, upper_contour, lower_contour, p=0.12, verbose = 0):\n    '''\n        input:\n            mask (H, W) with femur is 1 and tibia is 2\n            upper_contour, lower_contour\n        output: left_distances and right_distances vectors\n    '''\n    x_min = max(lower_contour[0,0],upper_contour[0,0])\n    x_max = min(lower_contour[-1,0],upper_contour[-1,0])\n    lower_contour = lower_contour[(lower_contour[:,0]>=x_min) & (lower_contour[:,0]<=x_max)]\n    \n    left, right = getMiddle(mask, lower_contour, verbose = verbose)\n    \n    left_idx = np.where(lower_contour[:,0] == left)[0][0]\n    right_idx = np.where(lower_contour[:,0] == right)[0][0]\n#     left_lower_contour = lower_contour[left_idx:]\n#     right_lower_contour = lower_contour[:right_idx+1][::-1]\n\n    left_lower_contour = lower_contour[(lower_contour[:,0]<=left) & (lower_contour[:,0]>=x_min) ]\n    right_lower_contour = lower_contour[(lower_contour[:,0]>=right) & (lower_contour[:,0]<=x_max)][::-1]\n\n    left_upper_contour = upper_contour[(upper_contour[:,0]<=left) & (upper_contour[:,0]>=x_min)]\n    right_upper_contour = upper_contour[(upper_contour[:,0]>=right) & (upper_contour[:,0]<=x_max)][::-1]\n\n    if verbose == 1:\n        temp = draw_points(mask*127, left_lower_contour, color = (0, 255, 0), thickness = 5)\n        temp = draw_points(temp, right_lower_contour, color = (0, 255, 0), thickness = 5)\n        temp = draw_points(temp, left_upper_contour, color = (255, 0, 0), thickness = 5)\n        temp = draw_points(temp, right_upper_contour, color = (255, 0, 0), thickness = 5)\n        # cv2_imshow(temp)\n        # cv2.imwrite('center_cropped.png', temp)\n        plt.imshow(temp)\n    links =  list(zip(left_upper_contour,left_lower_contour)), list(zip(right_upper_contour,right_lower_contour))\n\n    temp = left_upper_contour, right_upper_contour, left_lower_contour, right_lower_contour\n\n    return left_lower_contour[:,1]-left_upper_contour[:,1], right_lower_contour[:,1] - right_upper_contour[:,1], links, temp\n\n\ndef getMiddle(mask, contour, verbose=0):\n    '''\n        use Linear Regression to construct a straight line to remove the bone segment from upper_contour and lower_contour\n        input: \n            mask (H, W) with femur is 1 and tibia is 2\n            lower_contour\n        output: 2 point (left and right) define the boundary within which every point of the bone segment is located\n    '''\n    X = contour[:, 0].reshape(-1, 1)\n    y = contour[:, 1]\n    reg = LinearRegression().fit(X, y)\n    i_min = np.argmin(y[int(len(y) * 0.2):int(len(y) * 0.8)]) + int(len(y) * 0.2)\n    left = i_min - 1\n    right = i_min + 1\n    left_check = False\n    right_check = False\n    if verbose == 1:\n        # print('get Middle 1')\n        cmask = draw_points(mask, contour, thickness=3, color=(255, 0, 0))\n        cmask = draw_points(cmask, np.hstack([X, reg.predict(X).reshape(-1, 1).astype('int')]),thickness = 5,\n                            color=(0, 255, 0))\n        # cv2.imwrite(\"lr_mask.png\", cmask)\n        cmask = draw_points(mask,[[X[i_min][0], y[i_min]]], thickness=5, color=(0, 0, 255))\n        cmask = draw_points(cmask,[[X[i_min+50][0], y[i_min+50]]], thickness=5, color=(0, 255, 0))\n        # cv2_imshow(cmask)\n        cv2_imshow(cmask)\n\n    while True:\n        while not left_check:\n            if y[left] > reg.predict(X[left].reshape(-1, 1)):\n                break\n            left -= 1\n        while not right_check:\n            if y[right] > reg.predict(X[right].reshape(-1, 1)):\n                break\n            right += 1\n        if verbose == 1:\n            print(\"left: \",left)\n            print(\"right: \" ,right)\n            # print('get middle 2')\n            cmask = draw_points(cmask, [contour[left]], thickness=5, color=(255, 255, 0))\n            cmask = draw_points(cmask, [contour[right]], thickness=5, color=(0, 255, 255))\n            # print(cmask.shape)\n            # cv2.imwrite(\"lr.png\", cmask)\n            # cv2_imshow(cmask)\n            # plt.show()\n            cv2_imshow(cmask)\n\n        left_min = np.argmin(y[int(len(y) * 0.2):left]) + int(len(y) * 0.2) if int(len(y) * 0.2) < left else left\n        right_min = np.argmin(y[right:int(len(y) * 0.8)]) + right if right < int(len(y) * 0.8) else right\n        if y[left_min] > reg.predict(X[left_min].reshape(-1, 1)):\n            left_check = True\n        if y[right_min] > reg.predict(X[right_min].reshape(-1, 1)):\n            right_check = True\n        if right_check and left_check:\n            break\n        left = left_min - 1\n        right = right_min + 1\n    return min(X.flatten()[left], X.flatten()[right]), max(X.flatten()[left], X.flatten()[right])","metadata":{"execution":{"iopub.status.busy":"2024-08-14T07:01:50.855253Z","iopub.execute_input":"2024-08-14T07:01:50.855637Z","iopub.status.idle":"2024-08-14T07:01:50.879883Z","shell.execute_reply.started":"2024-08-14T07:01:50.855604Z","shell.execute_reply":"2024-08-14T07:01:50.878523Z"},"trusted":true},"outputs":[],"execution_count":8},{"cell_type":"code","source":"def pooling_array(array, n, mode='mean'):\n    if mode == 'mean':\n        pool = lambda x: np.mean(x)\n    elif mode == 'min':\n        pool = lambda x: np.min(x)\n    elif mode == 'sum':\n        pool = lambda x: np.sum(x)\n\n    if n == 1:\n        return pool(array)\n\n    array_length = len(array)\n    if array_length < n:\n        return array\n    segment_length = array_length // n\n    remaining_elements = array_length % n\n\n    if remaining_elements == 0:\n        segments = np.split(array, n)\n    else:\n        mid = remaining_elements * (segment_length + 1)\n        segments = np.split(array[:mid], remaining_elements)\n        segments += np.split(array[mid:], n - remaining_elements)\n\n    segments = [pool(segment) for segment in segments]\n\n    return np.array(segments)\n\n\ndef pool_links(links, dim, mode=\"mean\"):\n    '''\n        links là 1 list gồm nhiều cặp tọa độ trên dưới (knee join space giữa lower_contour vs upper_contour) có dạng: \n        [(array([436, 421], dtype=int32), array([436, 451], dtype=int32)), (array([436, 421], dtype=int32), array([436, 451], dtype=int32)), ...]\n        đầu tiên lấy danh sách các tọa độ x của các pair coord này, pool nó y như pool distance, rồi filter links ban đầu để lấy các pair có x thuộc pooled\n\n    '''\n    pooled_x = pooling_array(np.array(links)[:, 0, 0], dim, mode)\n    filtered_pairs = []\n    for x in pooled_x:\n        for pair in links:\n            if pair[0][0] == int(x):\n                filtered_pairs.append(pair)\n                break  # Lấy 1 cặp và dừng lại\n    return filtered_pairs\n\n\ndef get_JSW(mask, dim=None, pool='mean', p=0.3, verbose=0):\n    '''\n        input: mask (H, W) with femur is 1 and tibia is 2\n        output: 2 distance vectors (left, right) (aggregated to <dim> by <pool>), links (list of pairs coords for each side)\n    '''\n    if isinstance(mask, str):\n        mask = cv2.imread(mask, 0)\n    if mask is None:\n        return np.zeros(10), np.zeros(10)\n    uc, lc = get_contours(mask, verbose=verbose)\n    left_distances, right_distances, links, contours = distance(mask, uc, lc, p=p, verbose=verbose)\n    if verbose:\n        # print('in getjsw')\n        temp = draw_points(mask * 127, contours[0], thickness=3, color=(255, 0, 0))\n        temp = draw_points(temp, contours[1], thickness=5, color=(255, 0, 0))\n        temp = draw_points(temp, contours[2], thickness=5, color=(0, 255, 0))\n        temp = draw_points(temp, contours[3], thickness=5, color=(0, 255, 0))\n        temp = draw_lines(temp, links[::6], color=(0, 0, 255), thickness=2)\n        # cv2_imshow(temp)\n        # cv2.imwrite(\"drawn_lines.png\", temp)\n    if dim:\n        left_distances = pooling_array(left_distances, dim, pool)\n        right_distances = pooling_array(right_distances, dim, pool)\n\n        \n    return left_distances, right_distances\n\n\ndef calculate_diff(left_jsw, right_jsw):\n    '''\n        input: left_distances and right_distances vectors\n        output: jsw_m and jsw_mm\n    '''\n    jsw_max = max(np.max(left_jsw), np.max(right_jsw))\n    jsw_max_side = np.argmax([np.max(left_jsw), np.max(right_jsw)])\n    if jsw_max_side == 0:\n        jsw_min = np.min(right_jsw)\n    else:\n        jsw_min = np.min(left_jsw)\n    \n    diff_mean = abs(np.mean(left_jsw) - np.mean(right_jsw)) / jsw_max\n    diff_max_min = (jsw_max - jsw_min) / jsw_max\n\n    return diff_mean, diff_max_min\n\n\ndef calculate_jsw_info(left_jsw, right_jsw):\n    '''\n        input: left_distances and right_distances vectors\n        output: % diff, mean_left, mean_right, side_min (0 is left, 1 is right), index with value min (in side min), value min (in side min)\n    '''\n    mean_left = np.mean(left_jsw)\n    mean_right = np.mean(right_jsw)\n\n    side_min, index_min, value_min = (0, np.argmin(left_jsw), np.min(left_jsw)) if mean_left <= mean_right else (1, np.argmin(right_jsw), np.min(right_jsw)) \n\n    diff_percentage = np.abs((mean_left - mean_right) / mean_right) * 100\n\n    return diff_percentage, mean_left, mean_right, side_min, index_min, value_min","metadata":{"execution":{"iopub.status.busy":"2024-08-14T07:01:50.881665Z","iopub.execute_input":"2024-08-14T07:01:50.882041Z","iopub.status.idle":"2024-08-14T07:01:50.901591Z","shell.execute_reply.started":"2024-08-14T07:01:50.882011Z","shell.execute_reply":"2024-08-14T07:01:50.900448Z"},"trusted":true},"outputs":[],"execution_count":9},{"cell_type":"code","source":"def draw_points(image, points, color=None, random_color=False, same=True, thickness=1):\n    if color is None and not random_color:\n        color = (0, 255, 0)  # Màu mặc định là xanh lá cây (BGR)\n    if random_color:\n        color = (random.randint(0, 255), random.randint(0, 255), random.randint(0, 255))\n\n    image = to_color(image)\n\n    for point in points:\n        if random_color and not same:\n            color = (random.randint(0, 255), random.randint(0, 255), random.randint(0, 255))\n\n        x, y = point\n        image = cv2.circle(image, (x, y), thickness, color, -1)  # Vẽ điểm lên ảnh\n    return image\n\n\ndef draw_lines(image, pairs, color=None, random_color=False, same=True, thickness=1):\n    image_with_line = to_color(np.copy(image))\n\n    if color is None and not random_color:\n        color = (255, 0, 0)  # Màu mặc định là xanh lá cây (BGR)\n    if random_color:\n        color = (random.randint(0, 255), random.randint(0, 255), random.randint(0, 255))\n\n    # Vẽ đường thẳng dựa trên danh sách các cặp điểm\n    for pair in pairs:\n\n        if random_color and not same:\n            color = (random.randint(0, 255), random.randint(0, 255), random.randint(0, 255))\n\n        start_point = pair[0]\n        end_point = pair[1]\n        image_with_line = cv2.line(image_with_line, start_point, end_point, color, thickness)\n        image_with_line = cv2.circle(image_with_line, start_point, thickness + 1, color, -1)\n        image_with_line = cv2.circle(image_with_line, end_point, thickness + 1, color, -1)\n\n    return image_with_line\n\n\ndef center(contour):\n    idx = len(contour) // 2\n    return contour[idx]\n\n\ndef to_color(image):\n    if len(image.shape) == 3 and image.shape[-1] == 3:\n        return image\n    return cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n\n\ndef to_gray(image):\n    if len(image.shape) == 3 and image.shape[-1] == 3:\n        return cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n    return image\n\n\ndef cv2_imshow(images):\n    if not isinstance(images, list):\n        images = [images]\n\n    num_images = len(images)\n\n    # Hiển thị ảnh đơn lẻ trực tiếp bằng imshow\n    if num_images == 1:\n        image = images[0]\n        if len(image.shape) == 3 and image.shape[2] == 3:\n            # Ảnh màu (RGB)\n            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n            plt.imshow(image_rgb)\n        else:\n            # Ảnh xám\n            plt.imshow(image, cmap='gray')\n\n        plt.axis(\"off\")\n        plt.show()\n    else:\n        # Hiển thị nhiều ảnh trên cùng một cột\n        fig, ax = plt.subplots(num_images, 1, figsize=(4, 4 * num_images))\n\n        for i in range(num_images):\n            image = images[i]\n            if len(image.shape) == 3 and image.shape[2] == 3:\n                # Ảnh màu (RGB)\n                image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n                ax[i].imshow(image_rgb)\n            else:\n                # Ảnh xám\n                ax[i].imshow(image, cmap='gray')\n\n            ax[i].axis(\"off\")\n\n        plt.tight_layout()\n        plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-08-14T07:01:50.903413Z","iopub.execute_input":"2024-08-14T07:01:50.903789Z","iopub.status.idle":"2024-08-14T07:01:50.922554Z","shell.execute_reply.started":"2024-08-14T07:01:50.903758Z","shell.execute_reply":"2024-08-14T07:01:50.921246Z"},"trusted":true},"outputs":[],"execution_count":10},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"seg_model = Segmenter()","metadata":{"execution":{"iopub.status.busy":"2024-08-14T07:01:50.923834Z","iopub.execute_input":"2024-08-14T07:01:50.924217Z","iopub.status.idle":"2024-08-14T07:01:51.164557Z","shell.execute_reply.started":"2024-08-14T07:01:50.924188Z","shell.execute_reply":"2024-08-14T07:01:51.163219Z"},"trusted":true},"outputs":[],"execution_count":11},{"cell_type":"code","source":"DIR = '/kaggle/input/knee-osteoarthritis-dataset-with-severity'","metadata":{"execution":{"iopub.status.busy":"2024-08-14T07:04:13.933967Z","iopub.execute_input":"2024-08-14T07:04:13.935237Z","iopub.status.idle":"2024-08-14T07:04:13.940577Z","shell.execute_reply.started":"2024-08-14T07:04:13.935191Z","shell.execute_reply":"2024-08-14T07:04:13.939254Z"},"trusted":true},"outputs":[],"execution_count":25},{"cell_type":"code","source":"subsets = ['train', 'val', 'test']\n","metadata":{"execution":{"iopub.status.busy":"2024-08-14T07:04:14.476926Z","iopub.execute_input":"2024-08-14T07:04:14.477436Z","iopub.status.idle":"2024-08-14T07:04:14.482850Z","shell.execute_reply.started":"2024-08-14T07:04:14.477399Z","shell.execute_reply":"2024-08-14T07:04:14.481712Z"},"trusted":true},"outputs":[],"execution_count":26},{"cell_type":"code","source":"data = []","metadata":{"execution":{"iopub.status.busy":"2024-08-14T07:04:14.946388Z","iopub.execute_input":"2024-08-14T07:04:14.946809Z","iopub.status.idle":"2024-08-14T07:04:14.952482Z","shell.execute_reply.started":"2024-08-14T07:04:14.946770Z","shell.execute_reply":"2024-08-14T07:04:14.951139Z"},"trusted":true},"outputs":[],"execution_count":27},{"cell_type":"code","source":"for subset in subsets:\n    subset_path = os.path.join(DIR, subset)\n    labels = os.listdir(subset_path)\n    for label in labels:\n        image_paths = os.path.join(subset_path, label)\n        for image in os.listdir(image_paths):\n            try:\n                img = cv2.imread(os.path.join(image_paths, image))\n                mask = seg_model.segment(img)\n                left_distances, right_distances = get_JSW(mask, dim = 10, verbose = 0)\n                jsw_m, jsw_mm = calculate_diff(left_distances, right_distances)\n                diff_percentage, mean_left, mean_right, side_min, index_min, value_min = calculate_jsw_info(left_distances, right_distances)\n                data.append([image.replace(\".png\", \"\"), subset, label, jsw_m, jsw_mm, value_min])\n            except Exception:\n                print(f\"{subset}/{label}/{image}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-08-14T07:04:15.441204Z","iopub.execute_input":"2024-08-14T07:04:15.441714Z","iopub.status.idle":"2024-08-14T07:52:45.502023Z","shell.execute_reply.started":"2024-08-14T07:04:15.441680Z","shell.execute_reply":"2024-08-14T07:52:45.500388Z"},"trusted":true},"outputs":[],"execution_count":28},{"cell_type":"code","source":"path = \"/kaggle/input/knee-osteoarthritis-dataset-with-severity/test/4/9445318L.png\"\n# path = \"/kaggle/input/knee-osteoarthritis-dataset-with-severity/train/0/9003126L.png\"","metadata":{"execution":{"iopub.status.busy":"2024-08-14T07:03:14.016038Z","iopub.execute_input":"2024-08-14T07:03:14.016464Z","iopub.status.idle":"2024-08-14T07:03:14.022099Z","shell.execute_reply.started":"2024-08-14T07:03:14.016430Z","shell.execute_reply":"2024-08-14T07:03:14.020606Z"},"trusted":true},"outputs":[],"execution_count":19},{"cell_type":"code","source":"img = cv2.imread(path)\nmask = seg_model.segment(img)\nleft_distances, right_distances = get_JSW(mask, dim = 10, verbose = 0)\njsw_m, jsw_mm = calculate_diff(left_distances, right_distances)\ndiff_percentage, mean_left, mean_right, side_min, index_min, value_min = calculate_jsw_info(left_distances, right_distances)","metadata":{"execution":{"iopub.status.busy":"2024-08-14T07:03:14.509011Z","iopub.execute_input":"2024-08-14T07:03:14.510082Z","iopub.status.idle":"2024-08-14T07:03:14.871911Z","shell.execute_reply.started":"2024-08-14T07:03:14.510042Z","shell.execute_reply":"2024-08-14T07:03:14.870658Z"},"trusted":true},"outputs":[],"execution_count":20},{"cell_type":"code","source":"import pandas as pd","metadata":{"execution":{"iopub.status.busy":"2024-08-14T08:00:58.257424Z","iopub.execute_input":"2024-08-14T08:00:58.257910Z","iopub.status.idle":"2024-08-14T08:00:58.263072Z","shell.execute_reply.started":"2024-08-14T08:00:58.257856Z","shell.execute_reply":"2024-08-14T08:00:58.261809Z"},"trusted":true},"outputs":[],"execution_count":29},{"cell_type":"code","source":"df = pd.DataFrame(data, columns=['id', 'subset', 'kl_grade', 'jsw_mean', 'jsw_mm', 'jsw_min'])\ndf.to_csv('jsws.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-08-14T08:01:00.119098Z","iopub.execute_input":"2024-08-14T08:01:00.119504Z","iopub.status.idle":"2024-08-14T08:01:00.191601Z","shell.execute_reply.started":"2024-08-14T08:01:00.119473Z","shell.execute_reply":"2024-08-14T08:01:00.190504Z"},"trusted":true},"outputs":[],"execution_count":30},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null}]}